{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import annotations"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import h5py\n", "import torch\n", "from PIL import Image, ImageFile\n", "from torch.utils.data import Dataset, Subset\n", "from torchvision import transforms\n", "from torchvision.datasets import CIFAR10, ImageFolder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ImageFile.LOAD_TRUNCATED_IMAGES = True"]}, {"cell_type": "markdown", "metadata": {}, "source": ["from torchvision.transforms import Compose, Normalize, PILToTensor, Resize"]}, {"cell_type": "markdown", "metadata": {}, "source": ["deprecated in favor of MediumImagenetHDF5Dataset<br>\n", "class MediumImagenetDataset(Dataset):<br>\n", "    def __init__(self, img_size, split:str='train', augment=True):<br>\n", "        assert split in ['train', 'val', 'test']<br>\n", "        self.split = split<br>\n", "        self.augment = augment<br>\n", "        self.input_size = img_size<br>\n", "        self.transform = self._get_transforms()<br>\n", "        ds = ImageFolder(\"/data/medium-imagenet/data\")<br>\n", "        if split == 'train':<br>\n", "            self.dataset = Subset(ds, range(0, len(ds) * 9 // 10))<br>\n", "        else:<br>\n", "            self.dataset = Subset(ds, range(len(ds) * 9 // 10, len(ds)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["    def __getitem__(self, index):<br>\n", "        image, label = self.dataset[index]<br>\n", "        image = self.transform(image)<br>\n", "        return image, label"]}, {"cell_type": "markdown", "metadata": {}, "source": ["    def __len__(self):<br>\n", "        return len(self.dataset)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["    def _get_transforms(self):<br>\n", "        transform = []<br>\n", "        transform.append(transforms.PILToTensor())<br>\n", "        transform.append(lambda x: x.to(torch.float))<br>\n", "        normalization = torch.Tensor([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])<br>\n", "        transform.append(transforms.Normalize(normalization[0], normalization[1]))<br>\n", "        if self.train and self.augment:<br>\n", "            transform.extend(<br>\n", "                [<br>\n", "                    transforms.RandomHorizontalFlip(),<br>\n", "                    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),<br>\n", "                ]<br>\n", "            )<br>\n", "        transform.append(transforms.Resize([self.input_size] * 2))<br>\n", "        return transforms.Compose(transform)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class MediumImagenetHDF5Dataset(Dataset):\n", "    def __init__(\n", "        self,\n", "        img_size,\n", "        split: str = \"train\",\n", "        filepath: str = \"/data/medium-imagenet/medium-imagenet-nmep-96.hdf5\",\n", "        augment: bool = True,\n", "    ):\n", "        assert split in [\"train\", \"val\", \"test\"]\n", "        self.split = split\n", "        self.augment = augment\n", "        self.input_size = img_size\n", "        self.transform = self._get_transforms()\n", "        self.file = h5py.File(filepath, \"r\")\n", "    def __getitem__(self, index):\n", "        image = self.file[f\"images-{self.split}\"][index]\n", "        if self.split != \"test\":\n", "            label = self.file[f\"labels-{self.split}\"][index]\n", "        else:\n", "            label = -1\n", "        image = self.transform(image)\n", "        label = torch.tensor(label, dtype=torch.long)\n", "        return image, label\n", "    def __len__(self):\n", "        return len(self.file[f\"images-{self.split}\"])\n", "    def _get_transforms(self):\n", "        transform = []\n", "        transform.append(lambda x: torch.tensor(x / 256).to(torch.float))\n", "        normalization = torch.Tensor([[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]])\n", "        transform.append(transforms.Normalize(normalization[0], normalization[1]))\n", "        transform.append(transforms.Resize([self.input_size] * 2))\n", "        if self.split == \"train\" and self.augment:\n", "            transform.extend(\n", "                [\n", "                    transforms.RandomHorizontalFlip(),\n", "                    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n", "                ]\n", "            )\n", "        return transforms.Compose(transform)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class CIFAR10Dataset(Dataset):\n", "    def __init__(self, img_size=32, train=True):\n", "        self.train = train\n", "        self.img_size = img_size\n", "        self.transform = self._get_transforms()\n", "        self.dataset = CIFAR10(root=\"/data/cifar10\", train=self.train, download=True)\n", "    def __getitem__(self, index):\n", "        image, label = self.dataset[index]\n", "        image = self.transform(image)\n", "        return image, label\n", "    def __len__(self):\n", "        return len(self.dataset)\n", "    def _get_transforms(self):\n", "        if self.train:\n", "            transform = [\n", "                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n", "                transforms.RandomHorizontalFlip(),\n", "                transforms.ToTensor(),\n", "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n", "                transforms.Resize([self.img_size] * 2),\n", "            ]\n", "        else:\n", "            transform = [\n", "                transforms.ToTensor(),\n", "                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n", "                transforms.Resize([self.img_size] * 2),\n", "            ]\n", "        return transforms.Compose(transform)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}